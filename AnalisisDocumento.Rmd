---
title: "Analisis Exploratorio"
author: "Miguel Angel G.G"
date: "11/Feb/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(plyr)
library(dplyr)
library(reshape2)
library(ggplot2)
library(psych)
library(caret)
library(knitr)
library(forcats)
library(cutpointr)
library(caretEnsemble)
library(DDoutlier)
```


### Revisión preeliminar de archivo


```{r pressure, echo=FALSE}
set.seed(142)
data <- read.csv("Credit_Card.csv")
str(data)
```
En este conjunto de datos, se tienen 30,000 registros, con 25 variables cada una. Algunos pertenecientes a datos demográficos, y otros a datos de su respectiva cuenta bancaria.

Los datos financieros BILL_AMTX y PAY_AMTX tienen magnitudes diferentes para cada usuario, por lo tanto dichas variables tendrán que ser escaladas en caso de usar regresión regularizada. 

Los datos categoricos (sexo, educación y estado marital) están codificados como enteros. Se procede a dejar las categorías explícitas:
```{r}
data$SEX <- factor(ifelse(data$SEX==1,"Hombre","Mujer"))

data$EDUCATION <- factor(mapvalues(data$EDUCATION,0:6,c("Desc","MaestriaD","Licenciatura","Prepa","Otra","Desc","Desc")))

data$MARRIAGE <- factor(mapvalues(data$MARRIAGE, 0:3, c("Otro","Casada","Soltera","Otro")))

colnames(data)[25] <- "default"
colnames(data)[7] <- "PAY_1"
```

Las columnas restantes son en realidad 3 variables distintas, con 6 observaciones cada una. Se emplea la operación melt para cumplir los criterios del "dataset ordenado".

```{r}
paycol <- melt(data,id.vars=colnames(data)[-(7:12)],measured.vars=7:12, variable.name = "MONTHSBEFORE",value.name = "PENDINGPAYS")

paycol$MONTHSBEFORE <- sub(".*([[:digit:]])",x=paycol$MONTHSBEFORE, replacement="\\1" )

billcol <- melt(data,id.vars=colnames(data)[-(13:18)],measured.vars=13:18, variable.name = "MONTHSBEFORE",value.name = "BILL")

billcol$MONTHSBEFORE <- sub(".*([[:digit:]])",x=billcol$MONTHSBEFORE, replacement="\\1" )

amcol <- melt(data,id.vars=colnames(data)[-(19:24)],measured.vars=19:24, variable.name = "MONTHSBEFORE",value.name = "AMORTIZATION")

amcol$MONTHSBEFORE <- sub(".*([[:digit:]])",x=amcol$MONTHSBEFORE, replacement="\\1" )

tdata <- select(data,c((1:6),25))
paycol <- select(paycol,c(1,20,21))
amcol <- select(amcol,c(1,20,21))
billcol <- select(billcol,c(1,20,21))

columns <- join_all(lst(paycol,amcol,billcol),by=c("ID","MONTHSBEFORE"))
tdata <- join(tdata,columns,by="ID") %>%
  arrange(ID,MONTHSBEFORE) %>%
  select(1,8,2,3,4,5,6,9,10,11,7)

tdata$default <- factor(as.numeric(tdata$default))
tdata$MONTHSBEFORE <- as.numeric(tdata$MONTHSBEFORE)


```


## Prevalencia de impago (actual)

```{r}
prevalence <- mean(data$default==1)
```

La prevalencia del incumplimiento de pago en el mes actual es del `r prevalence*100`%

## Correlación entre variables continuas y variable de interés.

Se obtiene una matriz de correlación para todas las variables numericas continuas:
```{r}
cor.plot(select(data,c(-1,-(3:5))))
```

Se observa que las variables con mayor correlación con la variable de interés son los registros de los pagos atrasados mes con mes (PAY_X), y el límite de crédito (LIMIT_BAL), en ese orden. Sin embargo, los registros del estado de cuenta y cantidad pagada mensualmente parecen no tener relación directa.

Mientras que los registros de las variables PAY_X y BILL_AMTX están fuertemente relacionados de manera interna a cada variable.

## Analisis de Variables Discretas

### Género

```{r}
data$default <- factor(data$default)
levels(data$default) <- c("No","Si")

ggplot(aes(x=SEX,fill=default),data=data)+geom_bar(position=position_fill())+labs(title="Probabilidad de impago",subtitle="Por género")+xlab("Género")+ylab("Probabilidad")+geom_hline(yintercept = prevalence)
```

Se observa una muy sutil diferencia en los porcentajes de probabilidad de impago. La linea horizontal marca la prevalencia. Para corroborar esta correlación, aunque sutil, se realiza un test chi-square.

```{r}
chisq.test(data$SEX,data$default)
```
Se verifica entonces la correlación entre género e incidencia de impago.

### Grado de Educación

```{r}
ggplot(aes(x=EDUCATION,fill=default),data=data)+geom_bar(position=position_fill())+labs(title="Probabilidad de Impago",subtitle="Por grado de educación")+xlab("Grado")+ylab("Probabilidad")+geom_hline(yintercept = prevalence)
```

En cuanto al grado educativo, se observan ligeras diferencias entre las categorias, resaltando las categorías "Desconocido" y "Otra", donde la probabilidad de impago es marcadamente menor. 

Sin embargo, se podría pensar que esta diferencia se debe a la escaza cantidad de registros en dichas categorías y que, por lo tanto, en realidad esa diferencia es debida a solo unas cuantas personas que ejercen mucha influencia en el porcentaje. Si construimos la tabla de contingencia para esta relación y realizamos un test chi-square...

```{r}
chisq.test(with(data,table(EDUCATION, default)))
```
El p-value para este test es muy bajo y por lo tanto verifica la relación.

### Estado Marital

```{r}
ggplot(aes(x=MARRIAGE,fill=default),data=data)+geom_bar(position=position_fill())+labs(title="Probabilidad de Impago",subtitle="Por estado marital")+xlab("Estado")+ylab("Probabilidad")+geom_hline(yintercept = prevalence)
```

La diferencia entre los grupos "Casado-Otro" es prácticamente nula, sin embargo, el grupo de Solteros tiene un menor indice de impago.

### Edad

```{r}
ggplot(aes(x=AGE,fill=default),data=data)+geom_bar(position=position_fill())+labs(title="Probabilidad de Impago",subtitle="Por edad")+xlab("Años")+ylab("Probabilidad de Impago")+geom_hline(yintercept = prevalence)
```

En el intevalo de 20 a 50 años se notan valores ligeramente menores que en el intervalo de 50 en adelante. Este ligera diferencia se puede deber a la relación de la edad con otras variables demográficas:

```{r}
ggplot(aes(x=AGE,fill=EDUCATION),data=data)+geom_bar(position = position_stack())+labs(title="Grado Educativo por edad")+xlab("Edad")+ylab("Cantidad")
```

En el intervalo de personas de alrededor de 30 años predomina la maestría, del cual se observó, es un grupo con menor indice de falta de pago.


```{r}
ggplot(aes(x=AGE,fill=MARRIAGE),data=data)+geom_bar(position =  position_stack())+labs(title="Estado Marital por Edad")+xlab("Edad")+ylab("Cantidad")
```

Además, en dicho grupo la mayoría son solteros, grupo que también se identificó con un menor índice de falta de pago.

## Analisis de Variables Continuas

### Historial de Retraso de Pagos
Como se puede ver en la matriz de correlación, los valores que tienen mayor correlación con respecto a la variable de interés (default) son los registros de la variable PAY_n, que representa el número de pagos vencidos acumulados cada mes. 

Sin embargo, y es de esperarse, los 6 observaciones de la variable PAY_n estan estrechamente relacionadas. Por lo que, incluir todas esas observaciones en un futuro modelo, puede incrementar la varianza de los coeficientes en una regresión. 

```{r}

tdata$MONTHSBEFORE <- as.factor(tdata$MONTHSBEFORE)

fcount <- tdata %>% filter(PENDINGPAYS>0) %>% group_by(MONTHSBEFORE) %>% summarise(cnt=length(ID))
fcount$default <- factor(rep(1,6))

ggplot(data=tdata,aes(x=MONTHSBEFORE, y=PENDINGPAYS, fill=default))+geom_boxplot(outlier.shape = NA, alpha=0.6)+labs(title="Pagos pendientes cada mes", subtitle="vs Impago")+ylab("Pagos Pendientes")+xlab("Meses antes")+geom_text(data=fcount,aes(x=MONTHSBEFORE,label=cnt,y=3))+scale_y_continuous(breaks=seq(-2,5,1))+coord_cartesian(ylim=c(-2,5))
```

Solo el primer registro inmediatamente anterior tiene los promedios para ambos grupos en un valor distinto. Los demás registros, especialmente el 5 y 6, no parecen aportar mucho criterio, al momento de discriminar a los grupos. Gradualmente, el grupo de impago fue desplazando su rango intercuartílico, siendo cada vez más irregulares. Cabe resaltar que, no parece haber una cantidad significativa de casos irregulares en los meses -5 y -6. Lo que puede sugerir que este dataset fue constituido por clientes con poca antiguedad, o recién regularizados. 

Se grafica la distribución de los valores de PAY_1 (el registro más actual y por ende, el más significativo para la probabilidad impago").


```{r}
ggplot(aes(x=PAY_1,fill=default),data=data)+geom_bar(alpha=0.4, position= position_stack())+labs(title="Probabilidad de impago",subtitle = "En función del número de pagos vencidos el mes anterior")+xlab("Pagos atrasados")+ylab("Probabilidad de Impago")+coord_cartesian(xlim=c(-4,10))+geom_hline(yintercept = prevalence)+geom_vline(xintercept = 0)+coord_cartesian(xlim=c(-5,5))+scale_x_continuous(breaks=seq(-5,5,1))
```

Se aprecia un notable incremento en la probabilidad de impago cuando el número de pagos vencidos acumulados el mes anterior es mayor a 1. La probabilidad pasa a ser mayor que 50% cuando se tienen dos pagos atrasados. Por lo que cualquier usuario que tenga dos pagos atrasados es más probable que empeore, y consecuentemente aumente aún más la probabilidad de empeorar en los meses siguientes.

Se realiza un t-test para tener certeza en la existencia de esta diferencia en las distribuciones:
```{r}
t.test(data$PAY_1,as.numeric(data$default),paired=FALSE)
```


### Límite de Crédito

```{r warning=FALSE}
ggplot(aes(x=LIMIT_BAL, fill=default),data=tdata)+geom_density(alpha=0.3)+labs(title="Límite de Crédito")+ylab("Proporción")+xlab("Límite de Crédito [$]")
```

Se puede observar que, conforme el límite de crédito aumenta, disminuye la proporción de usuarios que incumplen el pago. 

### Historial del Estado de Cuenta

```{r}
tdata$MONTHSBEFORE <- factor(tdata$MONTHSBEFORE)

ggplot(aes(x=MONTHSBEFORE, y=BILL, fill=default),data=tdata)+geom_boxplot(outlier.shape = NA, alpha=0.6)+geom_violin( alpha=0.6)+coord_cartesian(ylim=c(-20000,98000))+labs(title="Evolución y distribución",subtitle = "Del historial del Estado de Cuenta")+xlab("Meses antes")+ylab("Estado de Cuenta")
```

No hay un desplazamiento sustancial del promedio del estado de cuenta entre ambos grupos, sin embargo, se observa que el 3er cuartil del grupo de los incumplidores está por debajo del mismo cuantil para los cumplidores, lo que significa que los pagos más altos de los cumplidores por lo general son más altos que los pagos más altos de las incumplidores. Esto bien puede estar relacionado con que los usuarios incumplidores tienen límites de crédito más bajos.

Conforme pasa el tiempo, los estados de cuenta altos (valor que marca el 3er cuartil, a escala normalizada) de ambos grupos se van incrementando, aunque con mayor grado en el grupo de los cumplidores.

### Historial de Amortizaciones

```{r}
ggplot(aes(x=MONTHSBEFORE, y=AMORTIZATION, fill=default),data=tdata)+geom_boxplot(outlier.shape = NA, alpha=0.3)+geom_violin( alpha=0.6)+coord_cartesian(ylim=c(-1000,10000))+labs(title="Evolución y distribución",subtitle = "Del historial de Amortizaciones")+xlab("Meses antes")+ylab("Cantidad Amortizada")
```

Para esta variable es más notoria una diferencia: El promedio de la cantidad pagada cada mes por los incumplidores es más baja que la cantidad promedio pagada por los cumplidores. La evolución de los pagos parece tener una tendencia creciente tanto para el promedio como para el tercer cuartil de ambos grupos, aunque al igual que en variable BILL_AMT, esta tendencia es más marcada en el grupo de los cumplidores.

## Creación de Variables Derivadas

### Historial de Amortizaciones

A pesar que la matriz de correlación indique que los valores individuales del historial de amortizaciones no estan relacionados directamente con la incidencia de impago, se puede deducir que el número de registros con pagos de $0 puede indicar una tendencia a faltar el siguiente pago.

```{r}
userg <- tdata %>% group_by(ID,default) %>% summarize(NNULLPAYMENTS = sum(AMORTIZATION==0))


ggplot(aes(x=NNULLPAYMENTS,fill=default),data=userg)+geom_bar(position=position_fill())+xlab("Numero de pagos nulos")+ylab("Probabilidad")+geom_hline(yintercept = prevalence)
```

Se observa un incremento en la probabilidad de impago conforme el número de pagos nulos es más alto. 


### Número de meses con pagos atrasados

Hasta ahora se revisó la correlación entre la incidencia de impago y el registro más actual de la variable PAY_X. Sin embargo, se puede sacar provecho de los registros anteriores, si se cuenta el número de meses con pagos atrasados, esto sugerirá que el usuario es un cierta medida irregular, y que por ende puede haber mayor probabilidad de que incumpla.

```{r}
seg <- tdata %>% group_by(ID,default) %>% summarise(IRREGMONTHS=sum(PENDINGPAYS>0))


ggplot(aes(x=IRREGMONTHS, fill=default),data=seg)+geom_bar(position=position_fill())+labs(title="Meses irregulares",subtitle = "vs Probabilidad de Impago")+ylab("Proporción")+xlab("Meses Irregulares")
```


Se observa una proporcionalidad lineal entre el número de meses con irregularidades y la probabilidad de impago.

### Porcentaje de Incremento del Estado de Cuenta

Al analizar la evolución de la variable BILL_X, lo más destacable era el desplazamiento gradual del tercer cuartil. Se construye una variable que indique cuánto incrementó el estado de cuenta desde el registro más antiguo.

```{r}
data <- mutate(data,INCRBILL=(BILL_AMT1-BILL_AMT6))
ggplot(aes(y=INCRBILL,x=default,fill=default),data=data)+geom_boxplot()+coord_cartesian(ylim=c(-4000,30000))+labs(title="Crecimiento del estado de Cuenta",subtitle = "vs Impago")+ylab("Cantidad [$]")+xlab("Impago")
```

Se confirma que el estado de cuenta de los cumplidores tiende a aumentar más que el estado de cuenta de los incumplidores.

###Incremento de la cantidad pagada

```{r}
data <- mutate(data,INCRPAYS=PAY_AMT1-PAY_AMT6)
ggplot(aes(y=INCRPAYS,x=default,fill=default),data=data)+geom_boxplot()+coord_cartesian(ylim=c(-700,3000))+labs(title="Crecimiento de los pagos",subtitle = "vs Impago")+ylab("Cantidad [$]")+xlab("Impago")
```

Se confirma que en el caso de los cumplidores aumenta en mayor medida el tamaño de sus pagos con el paso del tiempo.

## Reducción de Variables con PCA
```{r}
data <- join_all(list(data,select(userg,ID,NNULLPAYMENTS),select(seg,ID,IRREGMONTHS)),by="ID")

billpcacalc <- preProcess(data[,13:18],method="pca",pcaComp = 2)
amtpcacalc <- preProcess(data[,19:24],method="pca",pcaComp = 2)

rdata <- predict(billpcacalc,data)
rdata <- predict(amtpcacalc,rdata)

```

## Modelado

### Regresión Logística 

Se crearán tres modelos  de regresión logística:
1. Con variables originales
2. Con variables derivadas, exlcuyendo los 5 registros más antiguos para las variables históricas.
3. Con variables históricas BILL_X y PAY_AMT_X reducidas por PCA
4. Regresión Logística regularizada por modalidad ElasticNet. 

```{r warning=FALSE, cache=TRUE}
odata <- dplyr::select(data,2:25)
fdata <- dplyr::select(data,2,3,4,5,6,7,13,19,26,27,28,29,25)
rfdata <- dplyr::select(rdata,2,3,4,5,6,7,16,17,18,19,20,21,13)

cntl <- trainControl(method="cv", number=5, summaryFunction = twoClassSummary, classProbs = TRUE)

model1 <- train(default~.,data=odata,method="glm",metric="ROC", trControl= cntl)
model2 <- train(default~.,data=fdata,method="glm",metric="ROC", trControl= cntl)
model3 <- train(default~.,data=rfdata,method="glm",metric="ROC", trControl= cntl)

```


Para la regresión regularizada, se usa el dataset con todas las variables históricas y las variables derivadas, para que así el algoritmo de Red Elástica pueda realizar una selección automatizada de las características relevantes.

Para optimizar el modelo de Red Elástica, se emplea un grid para los parámetros alpha y lambda.



```{r cache=TRUE}
gr <- expand.grid(alpha=seq(0,1,0.1),lambda=seq(0.0001,0.02,0.001))
model4 <- train(default~.-ID,data=data,method="glmnet",metric="ROC",trControl=cntl,tuneGrid=gr,preProcess=c("center","scale"))
kable(model4$finalModel$tuneValue)
```

En efecto, es mejor realizar una mezcla entre los modelos Lasso y Ridge para optimizar el área bajo la curva ROC.


```{r}

predMat <- matrix(c(
  model1$finalModel$fitted.values,
  model2$finalModel$fitted.values,
  model3$finalModel$fitted.values,
  predict(model4,s=model4$finalModel$tuneValue$lambda,type="prob",data)[,2]
  ),30000,4)

suppressPackageStartupMessages(library(verification))
roc.plot(as.numeric(data$default)-1,predMat,legend=TRUE,plot.thres =NULL, ylab="% Detección (Sensibilidad)",xlab="% Falsa Alarma (1-Specificidad)",leg.text = c("Var. Originales","Var. Derivadas","Var. Reducidas","Regresión Regularizada"),main="ROC de Modelos de Regresión Logística")

```

Se obtienen las estimaciones del parámetro AUC como criterio para evaluar el rendimiento real de los modelos mediante Cross-Validation a 10 k-folds:

```{r}
kable(rbind(rbind(
  model1$results,
  model2$results,
  model3$results
  )[,2:7],
  model4$results[model4$results$alpha==model4$bestTune$alpha &         model4$results$lambda==model4$bestTune$lambda,3:8])
  ,caption="Rendimiento real estimado de Modelos R.L")
```

Es notoria la mejoría observada en el área bajo la curva ROC para los modelos que no usan todos los 6 registros pasados de las variables historicas. Las variables derivadas parecen demostrar efectividad al condensar la información de la dinamica de los registros BILL_X y PAY_AMTX ya que tiene prácticamente el mismo poder predictivo que aquel modelo que usa las variables reducidas por PCA.

Sin embargo, el modelo producido por regresión regularizada parece recolectar mejor (aunque en forma muy sutil) toda la información presente en el dataset. Se realiza un t test para corroborar que existe una mejora entre el modelo 2 y el 4:

```{r}
t.test(model2$resample$ROC,model4$resample$ROC,var.equal = FALSE,paired = FALSE)
```

El intervalo de confianza pasa por 0 y el p value es muy alto, por lo tanto, se puede concluir que ambos modelos tienen el mismo valor promedio de ROC.

Se opta por elegir el modelo 2 de entre estos modelos de regresión lineal por su bajo valor de varianza de ROC y de Sensitividad.

### Interpretación de Coeficientes del modelo 2

```{r}
coef <- as.data.frame(coef(model2$finalModel))
colnames(coef) <- "Valor"

a <- c(2,12:15) 
for(i in a){ coef[i,1] <- coef[i,1] * 100000}

coef$Valor <- exp(coef$Valor)
coef <- arrange(coef,desc(Valor))
ggplot(aes(x=fct_reorder(rownames(coef),Valor),y=Valor),data=coef)+geom_point(color="midnightblue")+
  labs(title="Coeficientes",subtitle="Del modelo de regresión logística 2")+
  theme(axis.text.x =  element_text(angle=90))+xlab("Variable")

```

El valor de la variable categórica Educación parece aportar mucho poder predictivo. Sin embargo, dado que gran parte de la población se ubica en los niveles Licenciatura-Maestría-Preparatoria, y aunado a que la diferencia entre sus respectivos coeficientes es baja, la variable Educación es en la práctica menos útil al momento de predecir.

La variable Meses Irregulares y Pagos pendientes el mes pasado (PAY_1) tienen un coeficiente alto, indicando relevancia en la predicción. Los coeficientes de las covariantes cuyas unidades son moneda, a excepción de PAY_1, fueron multiplicadas por 100,000 antes de exponenciar para hacer más visible su influencia.


### Modelos Alternativos

Además, se construirán adicionalmente:

5. Bosque aleatorio en base a variables derivadas
6. Máquina de Soporte Vectorial Lineal en base a variables derivadas.
7. Modelo de Análisis de Discriminante Lineal en base a variables originales.
8. Red Neuronal en base a variables derivadas.


```{r cache=TRUE}
model5 <- train(default~.,data=fdata,method="rf",metric="ROC",trControl=cntl)

imp <- dplyr::arrange(data.frame(model5$finalModel$importance),desc(MeanDecreaseGini))

ggplot(aes(x=fct_reorder(rownames(imp),-MeanDecreaseGini),y=MeanDecreaseGini),data=imp)+geom_point(color="midnightblue")+
    labs(title="Importancia de las variables",subtitle="Según el descenso del Indice Gini")+
    theme(axis.text.x =  element_text(angle=90))+xlab("Variable")
```

Se enlistan en orden decreciente las variables dentro del modelo RandomForest de 500 arboles por importancia según el criterio Gini. El más importante es la cantidad de pagos pendientes el mes pasado, seguido de dos variables derivadas y los registros más recientes del estado de cuenta, y cantidad pagada.


La matriz de confusion para este modelo, con un punto de corte de 0.5:

```{r}
confusionMatrix(model5$finalModel$predicted,data$default,positive="Si")
```


Para la SVM se hará un barrido del parámetro Costo. (Deshabilitado temporalmente)

```{r cache=TRUE}
gr <- expand.grid(C=c(0.01,0.03,0.05,0.75,1,2))

set.seed(4345)
model6 <- train(default~.,data=fdata,method="svmLinear",metric="ROC",trControl=trainControl(method="none", classProbs = TRUE, summaryFunction = twoClassSummary),preProcess=c("center","scale"))
```

Para optimizar la red neuronal se usa un barrido de los parámetros size (número de neuronas en la única capa oculta) y decay (el parámetro de penalización, evita el sobreajuste).

```{r cache=TRUE, message=FALSE, warning= FALSE, results=FALSE}

model7 <- train(default~.,data=fdata,method="lda",metric="ROC",trControl=cntl,preProcess=c("center","scale"))

model8 <- train(default~.,data=fdata,method="nnet",trControl=cntl,preProcess=c("center","scale"),tuneGrid=expand.grid(size=seq(3,10,1), decay=c(0.1)),metric="ROC")


predMat <- matrix(c(
  model5$finalModel$votes[,2],
  predict(model6,fdata,"prob")[,2],
  predict(model7,fdata,"prob")[,2],
  model8$finalModel$fitted.values
  ),30000,4)
```
```{r}
roc.plot(as.numeric(data$default)-1,predMat,legend=TRUE,plot.thres =NULL, ylab="% Detección (Sensibilidad)",xlab="% Falsa Alarma (1-Specificidad)",leg.text = c("Random Forest","SVM","LDA","Neural Network"), main="ROC de Modelos Alternativos")
```

El modelo de red neuronal parece, a priori, desempeñarse notoriamente mejor que el siguiente mejor modelo, el basado en Random Forest.

Los valores estimados de AUC reales para estos modelos: 

```{r}
kable(rbind(
  model5$results[model5$results$mtry==model5$bestTune$mtry,2:7],
  model7$results[,2:7],
  model8$results[model8$results$size==model8$bestTune$size,3:8]
  )
  ,caption="Rendimiento real estimado de Modelos Alternativos")
```

Se realiza un t test con los varios datos de ROC generados por validación cruzada durante el entrenamiento:

```{r}
t.test(model5$resample$ROC,model8$resample$ROC,var.equal = FALSE, paired=FALSE)
```
El p-value indica una probabilidad del 2% de obtener esta diferencia entre los valores de ROC para ambos modelos por pura casualidad. Por lo tanto se considera al modelo de redes neuronales, superior respecto a la métrica ROC.

### Ensamble de Modelos

Para contar los votos a favor de cada modelo, se calculan los puntos de corte óptimos según el criterio de Costo de Clasificación errónea. Para esto, se establece el costo de tener un falso positivo. En el contexto del proyecto, esto sería el costo de brindar atención a un cliente marcado como potencial a que incumpla el pago, cuando sí pagará. Además, se establece el costo de tener un falso negativo, es decir, el costo de no atender un futuro usuario del cual sí faltará el siguiente pago, o dicho de otra forma, la cantidad que adeudará dicho usuario. 

Estos valores deben ser establecidos con criterio propio del área bancaria. para efectos de ejemplo, se establece una relación 1:3 en el costo de falso positivo y falso negativo.

```{r message=FALSE}

cfp <- 1
cfn <- 5

comp <- data.frame(Reg=predict(model4,s=model4$finalModel$tuneValue$lambda,type="prob",data)[,2],RandFor=model5$finalModel$votes[,2],NeuralNet=model8$finalModel$fitted.values,LinDiscr=predict(model7,fdata,"prob")[,2],Impago=data$default)

for(i in 1:4){
comp[,i] <- ifelse(comp[,i]> cutpointr(x=comp[,i] ,class=comp$Impago, method=minimize_metric, metric = misclassification_cost,cost_fp=cfp,cost_fn=cfn,)$optimal_cutpoint,1,0)
}


kable(head(comp,5),caption="Votos a favor para cada usuario")
```
Para ensamblar estos cuatro modelos, se repite su entrenamiento bajo los mismos índices de los folds en la validación cruzada:
```{r cache=TRUE, message=FALSE, warning= FALSE, results=FALSE}
combo <- caretList(default~.,data=fdata,trControl=cntl,metric="ROC", tuneList =list(
  m1=caretModelSpec(method="glm"),
  m2=caretModelSpec(method="rf"),
  m3=caretModelSpec(method="lda",preProcess=c("center","scale")),
  m4=caretModelSpec(method="nnet",preProcess=c("center","scale"),tuneGrid=expand.grid(size=seq(3,10,1), decay=c(0.1)))
  ))
modelCor(resamples(combo))
```
Los 4 modelos tienen altos valores de correlación, por lo tanto, puede no ser útil ensamblarlos.

```{r}
ens <- caretEnsemble(combo,metric="ROC",trControl=cntl)
ens$ens_model$results
```
```{r}
t.test(ens$ens_model$resample$ROC,model8$resample$ROC)
```
El t-test de los valores de ROC obtenidos durante la validación cruzada en el entrenamiento del modelo ensamblado arroja un p-value elevado. No hay mejora significativa.

### Resultados del Mejor Predictor

Se selecciona la Red Neuronal, con punto de corte optimizado según el criterio antes descrito, y se obtienen los siguientes resultados:

```{r}
confusionMatrix(factor(comp$NeuralNet,labels=c("No","Si")),data$default,positive="Si")
```

## Identificación de Anomalías

Se emplea el _Factor de Anomalía Local_ para asignar a cada observación un valor que indica qué tan aislada esta dicha observación de respecto a sus observaciones vecinas. Para aplicar esta metodología, se estandarizan las variables numéricas y se crean dummys desde las variables categóricas.

```{r}


fnorm <- predict(preProcess(fdata,method=c("center","scale")),fdata)
m <- model.matrix(~.,fnorm)
fdata$LOF <- LOF(m,k=10)
quantile(fdata$LOF,.90)
```
El 90% de las observaciones se encuentran a dicho valor de LOF. Se procede a filtrar el 10% restante, considerándolas como anomalías.

```{r}
ndata <- filter(fdata,LOF<quantile(fdata$LOF,0.90))
```

Finalmente, se reentrena el modelo sin las anomalías.
```{r cache=TRUE, message=FALSE, warning= FALSE, results=FALSE}
model8m <- train(default~.,data=ndata,method="nnet",trControl=cntl,preProcess=c("center","scale"),tuneGrid=expand.grid(size=seq(3,10,1), decay=c(0.1)),metric="ROC")
```
```{r}
model8m$results[model8m$results$size==model8m$bestTune$size,3:8]
```
El valor promedio del área bajo la curva de ROC es ligeramente más alto que el modelo entrenado con anomalías. Se comprueba la hipótesis de la mejoría:
```{r}
t.test(model8m$resample$ROC,model8$resample$ROC)
```
En efecto, se comprueba una mejoría en la predicción.

Se calcula una nueva matriz de confusión para este nuevo modelo, con los datos de completos:

```{r}
predictions <- predict(model8m,fdata,type="prob")[,2]

pred <- ifelse(predictions> cutpointr(x=predictions ,class=fdata$default, method=minimize_metric, metric = misclassification_cost,cost_fp=cfp,cost_fn=cfn,)$optimal_cutpoint,1,0)

confusionMatrix(factor(pred,labels=c("No","Si")),fdata$default,positive = "Si")
```

